{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import soundfile as sf\n",
    "import librosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"audio/train.csv\")\n",
    "sample = df.iloc[100][\"filename\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = f\"audio/train/{sample}\"\n",
    "sr = 44100\n",
    "n_fft = int(0.025 * sr)\n",
    "hop_length = int(0.010 * sr)\n",
    "n_mels = 128\n",
    "y, _ = librosa.load(path, sr=sr)\n",
    "S = librosa.feature.melspectrogram(y=y, sr=sr, n_fft=n_fft, hop_length=hop_length, n_mels=n_mels, window='hamming')\n",
    "log_S = librosa.power_to_db(S, ref=np.max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "patch_size = 16\n",
    "overlap    = 6\n",
    "stride     = patch_size - overlap   # 10 :contentReference[oaicite:5]{index=5}\n",
    "\n",
    "# dimensiones del espectrograma\n",
    "n_freq, n_time = log_S.shape        # (128, ~100·t)\n",
    "\n",
    "# número de parches por dimensión\n",
    "n_patches_freq = (n_freq  - patch_size) // stride + 1\n",
    "n_patches_time = (n_time - patch_size) // stride + 1\n",
    "\n",
    "# total de parches N = n_patches_freq * n_patches_time\n",
    "N = n_patches_freq * n_patches_time  # debería coincidir con 12·ceil((100t−16)/10) :contentReference[oaicite:6]{index=6}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.lib.stride_tricks import sliding_window_view\n",
    "\n",
    "# crea una vista con ventanas de 16×16 :contentReference[oaicite:7]{index=7}\n",
    "windows = sliding_window_view(\n",
    "    log_S,\n",
    "    window_shape=(patch_size, patch_size)\n",
    ")\n",
    "\n",
    "# windows tiene forma (n_freq-15, n_time-15, 16, 16);\n",
    "# muestreamos cada stride-ésimo elemento\n",
    "patches = windows[\n",
    "    ::stride,        # freq\n",
    "    ::stride,        # time\n",
    "    :, :             # dentro de cada ventana\n",
    "]\n",
    "# aplanamos los dos primeros ejes en uno solo:\n",
    "patches = patches.reshape(-1, patch_size, patch_size)  # (N, 16, 16)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Procesados 0 audios de 62191\n",
      "Procesados 100 audios de 62191\n",
      "Procesados 200 audios de 62191\n",
      "Procesados 300 audios de 62191\n",
      "Procesados 400 audios de 62191\n",
      "Procesados 500 audios de 62191\n",
      "Procesados 600 audios de 62191\n",
      "Procesados 700 audios de 62191\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[65]\u001b[39m\u001b[32m, line 31\u001b[39m\n\u001b[32m     28\u001b[39m     y = np.pad(y, (\u001b[32m0\u001b[39m, \u001b[38;5;28mint\u001b[39m(sr * duration) - \u001b[38;5;28mlen\u001b[39m(y)))\n\u001b[32m     30\u001b[39m \u001b[38;5;66;03m# 4. Mel-spectrogram → dB\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m31\u001b[39m S     = \u001b[43mlibrosa\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfeature\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmelspectrogram\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     32\u001b[39m \u001b[43m            \u001b[49m\u001b[43my\u001b[49m\u001b[43m=\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msr\u001b[49m\u001b[43m=\u001b[49m\u001b[43msr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     33\u001b[39m \u001b[43m            \u001b[49m\u001b[43mn_fft\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_fft\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhop_length\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhop_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     34\u001b[39m \u001b[43m            \u001b[49m\u001b[43mn_mels\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_mels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwindow\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mhamming\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\n\u001b[32m     35\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     36\u001b[39m log_S = librosa.power_to_db(S, ref=np.max)  \u001b[38;5;66;03m# (128, ~100·t)\u001b[39;00m\n\u001b[32m     38\u001b[39m \u001b[38;5;66;03m# 5. Extraer parches 16×16 con solape 6 → stride=10\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/DL/lib/python3.12/site-packages/librosa/feature/spectral.py:2148\u001b[39m, in \u001b[36mmelspectrogram\u001b[39m\u001b[34m(y, sr, S, n_fft, hop_length, win_length, window, center, pad_mode, power, **kwargs)\u001b[39m\n\u001b[32m   2135\u001b[39m S, n_fft = _spectrogram(\n\u001b[32m   2136\u001b[39m     y=y,\n\u001b[32m   2137\u001b[39m     S=S,\n\u001b[32m   (...)\u001b[39m\u001b[32m   2144\u001b[39m     pad_mode=pad_mode,\n\u001b[32m   2145\u001b[39m )\n\u001b[32m   2147\u001b[39m \u001b[38;5;66;03m# Build a Mel filter\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m2148\u001b[39m mel_basis = \u001b[43mfilters\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmel\u001b[49m\u001b[43m(\u001b[49m\u001b[43msr\u001b[49m\u001b[43m=\u001b[49m\u001b[43msr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_fft\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_fft\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2150\u001b[39m melspec: np.ndarray = np.einsum(\u001b[33m\"\u001b[39m\u001b[33m...ft,mf->...mt\u001b[39m\u001b[33m\"\u001b[39m, S, mel_basis, optimize=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m   2151\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m melspec\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/DL/lib/python3.12/site-packages/librosa/filters.py:228\u001b[39m, in \u001b[36mmel\u001b[39m\u001b[34m(sr, n_fft, n_mels, fmin, fmax, htk, norm, dtype)\u001b[39m\n\u001b[32m    225\u001b[39m fftfreqs = fft_frequencies(sr=sr, n_fft=n_fft)\n\u001b[32m    227\u001b[39m \u001b[38;5;66;03m# 'Center freqs' of mel bands - uniformly spaced between limits\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m228\u001b[39m mel_f = \u001b[43mmel_frequencies\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_mels\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfmin\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfmin\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfmax\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfmax\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhtk\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhtk\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    230\u001b[39m fdiff = np.diff(mel_f)\n\u001b[32m    231\u001b[39m ramps = np.subtract.outer(mel_f, fftfreqs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/DL/lib/python3.12/site-packages/librosa/core/convert.py:1728\u001b[39m, in \u001b[36mmel_frequencies\u001b[39m\u001b[34m(n_mels, fmin, fmax, htk)\u001b[39m\n\u001b[32m   1724\u001b[39m max_mel = hz_to_mel(fmax, htk=htk)\n\u001b[32m   1726\u001b[39m mels = np.linspace(min_mel, max_mel, n_mels)\n\u001b[32m-> \u001b[39m\u001b[32m1728\u001b[39m hz: np.ndarray = \u001b[43mmel_to_hz\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhtk\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhtk\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1729\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m hz\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/DL/lib/python3.12/site-packages/librosa/core/convert.py:1296\u001b[39m, in \u001b[36mmel_to_hz\u001b[39m\u001b[34m(mels, htk)\u001b[39m\n\u001b[32m   1294\u001b[39m min_log_hz = \u001b[32m1000.0\u001b[39m  \u001b[38;5;66;03m# beginning of log region (Hz)\u001b[39;00m\n\u001b[32m   1295\u001b[39m min_log_mel = (min_log_hz - f_min) / f_sp  \u001b[38;5;66;03m# same (Mels)\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1296\u001b[39m logstep = \u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlog\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m6.4\u001b[39;49m\u001b[43m)\u001b[49m / \u001b[32m27.0\u001b[39m  \u001b[38;5;66;03m# step size for log region\u001b[39;00m\n\u001b[32m   1298\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m mels.ndim:\n\u001b[32m   1299\u001b[39m     \u001b[38;5;66;03m# If we have vector data, vectorize\u001b[39;00m\n\u001b[32m   1300\u001b[39m     log_t = mels >= min_log_mel\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import librosa\n",
    "import torch\n",
    "from numpy.lib.stride_tricks import sliding_window_view\n",
    "\n",
    "# --- Parámetros de audio y parches (igual que antes) ---\n",
    "sr         = 44100\n",
    "n_fft      = int(0.025 * sr)\n",
    "hop_length = int(0.010 * sr)\n",
    "n_mels     = 128\n",
    "patch_size = 16\n",
    "overlap    = 6\n",
    "stride     = patch_size - overlap\n",
    "duration   = 3.0  # segundos\n",
    "\n",
    "# --- Leer CSV y directorio de audios ---\n",
    "df        = pd.read_csv(\"audio/train.csv\")\n",
    "audio_dir = \"audio/train\"\n",
    "\n",
    "# Determinamos las columnas de etiqueta (todas menos 'filename')\n",
    "label_cols = [c for c in df.columns if c != \"filename\"]\n",
    "\n",
    "data_list  = []\n",
    "label_list = []\n",
    "\n",
    "for _, row in df.iterrows():\n",
    "    # 1) Carga y pad a duración fija\n",
    "    y, _ = librosa.load(f\"{audio_dir}/{row['filename']}\", sr=sr, duration=duration)\n",
    "    if len(y) < int(sr * duration):\n",
    "        print(f\"Audio {row['filename']} es más corto que {duration} segundos, padding...\")\n",
    "        y = np.pad(y, (0, int(sr * duration) - len(y)))\n",
    "\n",
    "    # 2) Mel-spectrogram → dB\n",
    "    S     = librosa.feature.melspectrogram(\n",
    "                y=y, sr=sr,\n",
    "                n_fft=n_fft, hop_length=hop_length,\n",
    "                n_mels=n_mels, window=\"hamming\"\n",
    "            )\n",
    "    log_S = librosa.power_to_db(S, ref=np.max)\n",
    "\n",
    "    # 3) Extraer parches 16×16 con solape 6 → stride=10\n",
    "    windows = sliding_window_view(log_S, window_shape=(patch_size, patch_size))\n",
    "    patches = windows[::stride, ::stride]               \n",
    "    patches = patches.reshape(-1, patch_size, patch_size)  # (N,16,16)\n",
    "\n",
    "    data_list.append(patches)\n",
    "\n",
    "    # 4) Extraer vector de etiquetas multi‑hot\n",
    "    labels = row[label_cols].values.astype(np.int64)     # e.g. [0,0,1,0,...]\n",
    "    label_list.append(labels)\n",
    "\n",
    "# 5) Apilar en arrays numpy\n",
    "data_array   = np.stack(data_list,  axis=0)   # (num_samples, N, 16, 16)\n",
    "labels_array = np.stack(label_list, axis=0)   # (num_samples, num_classes)\n",
    "\n",
    "# 6) Convertir a tensores PyTorch\n",
    "tensor_data   = torch.from_numpy(data_array).float()      # float para pasar al modelo\n",
    "tensor_labels = torch.from_numpy(labels_array).float()    # float para BCEWithLogitsLoss\n",
    "\n",
    "# 7) Guardar en un solo .pt\n",
    "torch.save(\n",
    "    {\"data\": tensor_data, \"labels\": tensor_labels, \"label_cols\": label_cols},\n",
    "    \"ast_multilabel_dataset.pt\"\n",
    ")\n",
    "print(\"Guardado ast_multilabel_dataset.pt con\",\n",
    "      tensor_data.shape, \"y\", tensor_labels.shape)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
